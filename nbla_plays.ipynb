{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Neuron Network\n",
    "In this section, we build very simply Nnabla model and save the model in a NNB file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-05 15:04:59,928 [nnabla][INFO]: Initializing CPU extension...\n"
     ]
    }
   ],
   "source": [
    "import nnabla as nn\n",
    "import nnabla.functions as F\n",
    "import nnabla.parametric_functions as PF\n",
    "import numpy as np\n",
    "import nnabla.initializer as I\n",
    "from save_nnp import save_nnp\n",
    "\n",
    "nn.parameter.clear_parameters()\n",
    "rng = np.random.seed(31024)\n",
    "initializer = I.UniformInitializer((-0.1, 0.1), rng=rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "nnp_file_name = 'simple_nn_0.nnp'\n",
    "nnb_file_name = 'simple_nn_0.nnb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = nn.Variable((1, 5))\n",
    "y = PF.affine(x, 1, w_init=initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3 4 5]]\n"
     ]
    }
   ],
   "source": [
    "x.d = np.array([1,2,3,4,5])\n",
    "print(x.d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7102661]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.forward()\n",
    "y.d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-05 15:05:01,670 [nnabla][INFO]: Saving simple_nn_0.nnp as nnp\n",
      "2020-05-05 15:05:01,672 [nnabla][INFO]: Saving /tmp/tmpx9ph3yml/network.nntxt as prototxt\n",
      "2020-05-05 15:05:01,675 [nnabla][INFO]: Parameter save (.protobuf): /tmp/tmpx9ph3yml/parameter.protobuf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'networks': [{'name': 'NN-0', 'batch_size': 1, 'outputs': {'y': <Variable((1, 1), need_grad=True) at 0x7f9fcb42a470>}, 'names': {'x': <Variable((1, 5), need_grad=False) at 0x7f9fcb405fb0>}}], 'executors': [{'name': 'Runtime', 'network': 'NN-0', 'data': ['x'], 'output': ['y']}]}\n"
     ]
    }
   ],
   "source": [
    "content = save_nnp(nnp_file_name, input={'x': x}, output={'y': y}, batchsize=batch_size)\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert from NNP to NNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert from NNP to NNB\n",
    "import subprocess, sys, os\n",
    "out = subprocess.Popen(['nnabla_cli', 'convert', '-b', '%d' % batch_size, nnp_file_name, nnb_file_name])\n",
    "assert(os.path.exists(nnb_file_name))\n",
    "assert(os.path.isfile(nnb_file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert from binary NNB to C-style NNB\n",
    "\n",
    "https://github.com/Jamesits/bin2array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnabla.utils.nnp_graph import NnpLoader\n",
    "# Read a .nnp file.\n",
    "nnp = NnpLoader(nnp_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nw_name = nnp.get_network_names()[0]\n",
    "net = nnp.get_network(nw_name)\n",
    "print(net.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(net.inputs)\n",
    "print(net.outputs)\n",
    "x = net.inputs['x']\n",
    "y = net.outputs['y']\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x.d = np.array([11,12,13,14,15])\n",
    "y.forward()  # You can execute a sub graph.\n",
    "print(\"y: %s\" % y.d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nnabla as nn\n",
    "import nnabla.functions as F\n",
    "import nnabla.parametric_functions as PF\n",
    "import numpy as np\n",
    "import nnabla.initializer as I\n",
    "\n",
    "nn.parameter.clear_parameters()\n",
    "\n",
    "rng = np.random.seed(31024)\n",
    "initializer = I.UniformInitializer((-0.1, 0.1), rng=rng)\n",
    "\n",
    "# create 16 random images 256x256 (RGB)\n",
    "x = nn.Variable((16, 3, 256, 256))\n",
    "x.d = np.random.random(x.shape)  # random input, just for example.\n",
    "\n",
    "y0 = PF.convolution(x, outmaps=64, kernel=(3, 3), pad=(1, 1), stride=(2, 2), w_init=initializer, name=\"conv1\", with_bias=False)\n",
    "y1 = F.relu(y0)\n",
    "y2 = PF.convolution(y1, outmaps=128, kernel=(3, 3), pad=(1, 1), stride=(2, 2), w_init=initializer, name=\"conv2\", with_bias=False)\n",
    "y3 = F.relu(y2)\n",
    "y4 = F.average_pooling(y3, kernel=y3.shape[2:])\n",
    "y5 = PF.affine(y4, 1, w_init=initializer)\n",
    "loss = F.mean(F.abs(y5 - 1.))\n",
    "loss.forward()  # Execute forward\n",
    "\n",
    "# We can check the current gradient of parameter.\n",
    "print(\"******* forward *******\")\n",
    "print(nn.get_parameters()[\"conv1/conv/W\"].g)\n",
    "\n",
    "loss.backward()\n",
    "print(\"******* backward *******\")\n",
    "print(nn.get_parameters()[\"conv1/conv/W\"].g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN with static graph\n",
    "In this section, we demonstrate:\n",
    " - building a simple graph\n",
    " - training model\n",
    " - running prediction (with the trained model)\n",
    " - saving trained model\n",
    " - loading trained model\n",
    " - running prediction (with the loaded model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits  # Only for dataset\n",
    "\n",
    "import nnabla as nn\n",
    "import nnabla.functions as F\n",
    "import nnabla.parametric_functions as PF\n",
    "import nnabla.solvers as S\n",
    "import nnabla.initializer as I\n",
    "from nnabla.monitor import tile_images\n",
    "from nnabla.utils.data_iterator import data_iterator_simple\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "nn.clear_parameters()\n",
    "nn.reset_array_preference()\n",
    "\n",
    "# set graph\n",
    "CNN_GRAPH = 1\n",
    "\n",
    "batch_size = 64\n",
    "h5_file_name = 'static_graph.h5'\n",
    "nnp_file_name = 'cnn_static_graph.nnp'\n",
    "nnb_file_name = 'cnn_static_graph.nnb'\n",
    "csrc_dir_name = 'cnn_static_graph_csrc'\n",
    "\n",
    "rng = np.random.seed(31024)\n",
    "initializer = I.UniformInitializer((-0.1, 0.1), rng=rng)\n",
    "\n",
    "imshow_opt = dict(cmap='gray', interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow_opt = dict(cmap='gray', interpolation='nearest')\n",
    "\n",
    "def plot_stats(digits):\n",
    "    print(\"Num images:\", digits.images.shape[0])\n",
    "    print(\"Image shape:\", digits.images.shape[1:])\n",
    "    print(\"Labels:\", digits.target[:10])\n",
    "    plt.imshow(tile_images(digits.images[:64, None]), **imshow_opt)\n",
    "\n",
    "\n",
    "def data_iterator_tiny_digits(digits, batch_size=batch_size, shuffle=False, rng=None):\n",
    "    def load_func(index):\n",
    "        \"\"\"Loading an image and its label\"\"\"\n",
    "        img = digits.images[index]\n",
    "        label = digits.target[index]\n",
    "        return img[None], np.array([label]).astype(np.int32)\n",
    "    return data_iterator_simple(load_func, digits.target.shape[0], batch_size, shuffle, rng, with_file_cache=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataset\n",
    "digits = load_digits(n_class=10)\n",
    "plot_stats(digits)\n",
    "print('type(digits) = %s' % type(digits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_iterator_tiny_digits(digits, batch_size=batch_size, shuffle=True)\n",
    "img, label = data.next()\n",
    "plt.imshow(tile_images(img), **imshow_opt)\n",
    "print(\"labels:\", label.reshape(8, 8))\n",
    "print(\"Label shape:\", label.shape)\n",
    "print('type(img) = %s, img.shape = %s' % (type(img), img.shape))\n",
    "print('type(label) = %s' % type(label))\n",
    "\n",
    "print(img[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build a graph\n",
    "> Note: we have to run only one section:\n",
    "    - build simple graph\n",
    "    - build more complex graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### build simple graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if CNN_GRAPH == 0:\n",
    "    # Forward pass\n",
    "    x = nn.Variable(img.shape)  # Define an image variable\n",
    "    with nn.parameter_scope(\"affine1\"):\n",
    "        y = PF.affine(x, 10)  # Output is 10 class\n",
    "\n",
    "    # Building a loss graph\n",
    "    t = nn.Variable(label.shape)  # Define an target variable\n",
    "    loss = F.mean(F.softmax_cross_entropy(y, t))  # Softmax Xentropy fits multi-class classification problems\n",
    "\n",
    "    print(\"Printing shapes of variables\")\n",
    "    print('x:', x.shape)\n",
    "    print('y:', y.shape)\n",
    "    print('t:', t.shape)\n",
    "    print('loss:', loss.shape)  # empty tuple means scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### build more complex graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if CNN_GRAPH == 1:\n",
    "    # Forward pass\n",
    "    x = nn.Variable(img.shape)  # Define an image variable\n",
    "    with nn.parameter_scope(\"affine1\"):\n",
    "        y0 = PF.convolution(x, outmaps=batch_size, kernel=(3, 3), pad=(1, 1), stride=(2, 2), w_init=initializer, name=\"conv1\", with_bias=False)\n",
    "        y1 = F.relu(y0)\n",
    "        # since the image is already too small, pooling does not make sense\n",
    "        # y2 = F.max_pooling(y1, kernel=y1.shape[2:])\n",
    "        y = PF.affine(y1, 10)  # Output is 10 class\n",
    "\n",
    "    # Building a loss graph\n",
    "    t = nn.Variable(label.shape)  # Define an target variable\n",
    "    loss = F.mean(F.softmax_cross_entropy(y, t))  # Softmax Xentropy fits multi-class classification problems\n",
    "\n",
    "    print(\"Printing shapes of variables\")\n",
    "    print('x:', x.shape)\n",
    "    print('y0:', y0.shape)\n",
    "    print('y1:', y1.shape)\n",
    "    print('y:', y.shape)\n",
    "    print('t:', t.shape)\n",
    "    print('loss:', loss.shape)  # empty tuple means scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a solver (gradient-based optimizer)\n",
    "learning_rate = 1e-3\n",
    "solver = S.Sgd(learning_rate)\n",
    "solver.set_parameters(nn.get_parameters())  # Set parameter variables to be updated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "n_epochs = 1000\n",
    "total_epochs = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for _ in range(n_epochs):\n",
    "    x.d, t.d = data.next()\n",
    "    loss.forward()\n",
    "    solver.zero_grad()  # Initialize gradients of all parameters to zero.\n",
    "    loss.backward()\n",
    "    solver.weight_decay(1e-5)  # Applying weight decay as an regularization\n",
    "    solver.update()\n",
    "    total_epochs = total_epochs + 1\n",
    "    if total_epochs % 100 == 0:  # Print for each 10 iterations\n",
    "        print('epoch=%d loss=%f' % (total_epochs, loss.d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "x.d, t.d = data.next()  # Here we predict images from training set although it's useless. \n",
    "y.forward()  # You can execute a sub graph.\n",
    "plt.imshow(tile_images(x.d), **imshow_opt)\n",
    "print(\"prediction:\")\n",
    "print(y.d.argmax(axis=1).reshape(8, 8))  # Taking a class index based on prediction score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_nnp(input, output, batchsize):\n",
    "    runtime_contents = {\n",
    "        'networks': [\n",
    "            {'name': 'Validation',\n",
    "             'batch_size': batchsize,\n",
    "             'outputs': output,\n",
    "             'names': input}],\n",
    "        'executors': [\n",
    "            {'name': 'Runtime',\n",
    "             'network': 'Validation',\n",
    "             'data': [k for k, _ in input.items()],\n",
    "             'output':[k for k, _ in output.items()]}]}\n",
    "    return runtime_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save parameters\n",
    "nn.save_parameters(h5_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = nn.Variable(x.shape)\n",
    "lab = nn.Variable(t.shape)\n",
    "img.d, lab.d = data.next()\n",
    "if CNN_GRAPH == 0:\n",
    "    content = save_nnp(input={'x': x}, output={'y': y, 'loss': loss, 't': t}, batchsize=batch_size)\n",
    "elif CNN_GRAPH == 1:\n",
    "    # content = save_nnp(input={'x': x}, output={'y': y, 'y0': y0, 'y1': y1, 'loss': loss, 't': t}, batchsize=batch_size)\n",
    "    content = save_nnp(input={'x': x}, output={'y': y, 'y0': y0, 'y1': y1}, batchsize=batch_size)\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nnabla.utils.save as save\n",
    "save.save(nnp_file_name, content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnabla.utils.nnp_graph import NnpLoader\n",
    "\n",
    "# load h5\n",
    "nn.load_parameters(h5_file_name)\n",
    "# Read a .nnp file.\n",
    "nnp = NnpLoader(nnp_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nw_name = nnp.get_network_names()[0]\n",
    "net = nnp.get_network(nw_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nw_name = nnp.get_network_names()[0]\n",
    "print('nw_name = %s' % nw_name)\n",
    "net = nnp.get_network(nw_name)\n",
    "print(net)\n",
    "# load h5\n",
    "nn.load_parameters(h5_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(net.inputs)\n",
    "print(net.outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = net.inputs['x']\n",
    "y = net.outputs['y']\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# prediction\n",
    "print('data.position=%d' % data.position)\n",
    "x.d, _ = data.next()  # Here we predict images from training set although it's useless. \n",
    "y.forward()  # You can execute a sub graph.\n",
    "plt.imshow(tile_images(x.d), **imshow_opt)\n",
    "print(\"prediction:\")\n",
    "print(y.d.argmax(axis=1).reshape(8, 8))  # Taking a class index based on prediction score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File format conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert from NNP to NNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert from NNP to NNB\n",
    "import subprocess, sys, os\n",
    "out = subprocess.Popen(['nnabla_cli', 'convert', '-b', '%d' % batch_size, nnp_file_name, nnb_file_name])\n",
    "assert(os.path.exists(nnb_file_name))\n",
    "assert(os.path.isfile(nnb_file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert from binary NNB to C-style NNB\n",
    "\n",
    "https://github.com/Jamesits/bin2array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert from NNP to C source\n",
    "This generated C source files are in the directory `csrc_dir_name`, with a GNUmakefile. This should be a good example of using the generated C source model.\n",
    "\n",
    "Requirements before compiling the C source:\n",
    "1. clone the official Nnabla C Runtime from https://github.com/sony/nnabla-c-runtime (without -fPIE flag) or https://github.com/mu-triv/nnabla-c-runtime (with -fPIE)\n",
    "2. compile Nnabla C Runtime (`make`)\n",
    "3. set these environment variables:\n",
    "    * `LD_LIBRARY_PATH` and `LIBRARY_PATH` (example: `nnabla-c-runtime/build/_CPack_Packages/Linux/ZIP/nnabla-c-runtime-1.2.0.dev1_c1-Linux/lib`)\n",
    "    * `C_INCLUDE_PATH` and `CPLUS_INCLUDE_PATH` (example: `nnabla-c-runtime/include`)\n",
    "    * Or you will need to modify the GNUmakefile\n",
    "\n",
    "The generated C source is compiled with the following command:\n",
    "```\n",
    "cd csrc_dir_name\n",
    "make\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert from NNP to CSRC\n",
    "import subprocess\n",
    "import pathlib\n",
    "pathlib.Path(csrc_dir_name).mkdir(parents=True, exist_ok=True) \n",
    "\n",
    "out = subprocess.Popen(['nnabla_cli', 'convert', '-b', '%d' % batch_size, '-O', 'CSRC', nnp_file_name, csrc_dir_name])\n",
    "assert(os.path.exists(nnb_file_name))\n",
    "assert(os.path.isdir(csrc_dir_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save 64 raw images\n",
    "These images are used with prediction later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_file = 'img_64010808.raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(prediction_file, 'wb') as fh:\n",
    "    print('data.position=%d' % data.position)\n",
    "    x.d, _ = data.next()\n",
    "    print('x.d.shape = %s' % str(x.d.shape))\n",
    "    print('type = %s' % type(x.d[0,0,0,0]))\n",
    "    fh.write(np.float32(x.d))\n",
    "plt.imshow(tile_images(x.d), **imshow_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert from binary raw images to C-style images\n",
    "\n",
    "https://github.com/Jamesits/bin2array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### display the prediction results\n",
    "> Note: execute this cell after the CSRC inference execution\n",
    "\n",
    "This cell displays the prediction result and allows to compare the result with the reference images.\n",
    "\n",
    "I assume that we execute the CSCR inference this way\n",
    "\n",
    "`./Validation_example ../img_64010808.raw output`\n",
    "\n",
    "> `img_64010808.raw` is defined in `prediction_file`\n",
    ">\n",
    "> `output` is the header of the output file names\n",
    "\n",
    "After executing the prediction in CSRC, we obtain several output data, such as `output_0.bin`, `output_1.bin`, `output_2.bin`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "yinf = nn.Variable(y.shape)\n",
    "prediction_result_file = os.path.join(csrc_dir_name, 'output_0.bin')\n",
    "with open(prediction_result_file, 'rb') as fh:\n",
    "    fbytes = fh.read()\n",
    "\n",
    "afloats = np.frombuffer(fbytes, dtype=np.float32)\n",
    "yinf.d = np.reshape(afloats, yinf.shape)\n",
    "print(yinf.d.argmax(axis=1).reshape(8, 8))  # Taking a class index based on prediction score.\n",
    "\n",
    "# load the reference images\n",
    "yref = nn.Variable(x.shape)\n",
    "with open(prediction_file, 'rb') as fh:\n",
    "    yref_d = fh.read()\n",
    "yref.d = np.reshape(np.frombuffer(yref_d, dtype=np.float32), yref.shape)\n",
    "# display the reference images\n",
    "plt.imshow(tile_images(yref.d), **imshow_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x=3; y=4; z=5\n",
    "a = np.random.randint(0, 10, size=(x,y,z))\n",
    "b = np.random.randint(0, 10, size=(x,y,z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nnabla as nn\n",
    "\n",
    "nn.set_auto_forward(True)\n",
    "\n",
    "x0 = nn.NdArray((a.shape))\n",
    "x0.data = a\n",
    "x1 = nn.NdArray((b.shape))\n",
    "x1.data = b\n",
    "print(\"x0=\", x0.data)\n",
    "print(\"x1=\", x1.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r = nn.functions.equal(x0, x1, n_outputs=-1, outputs=None)\n",
    "print(r, r.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = nn.functions.greater(x0, x1, n_outputs=-1, outputs=None)\n",
    "print(r, r.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = nn.Variable(x0.shape)\n",
    "x2.data = x0\n",
    "x3 = nn.Variable(x1.shape)\n",
    "x3.data = x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = nn.functions.greater(x2, x3, n_outputs=-1, outputs=None)\n",
    "print(r, r.d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nnabla.functions as F\n",
    "\n",
    "x = nn.Variable.from_numpy_array(np.random.rand(2, 3, 4))\n",
    "print(x)\n",
    "print(x.d)\n",
    "\n",
    "minval = F.min(x, axis=1)\n",
    "print(minval)\n",
    "print(minval.d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## function relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import nnabla.parametric_functions as PF\n",
    "import nnabla.functions as F\n",
    "\n",
    "x = nn.Variable((2, 3, 8, 8))\n",
    "x.d = np.random.random(x.shape)  # random input, just for example.\n",
    "\n",
    "nn.parameter.clear_parameters()\n",
    "with nn.parameter_scope('conv1') as param:\n",
    "    conv_out = PF.convolution(x, 2, (5, 5))\n",
    "    relu_out = F.relu(conv_out)\n",
    "    \n",
    "print(relu_out)\n",
    "print(relu_out.d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nnabla as nn\n",
    "import nnabla.parametric_functions as PF\n",
    "import nnabla.functions as F\n",
    "numbers = np.arange(start=-10.0, stop=10.0, step=.1, dtype=np.float)\n",
    "print(\"numbers.shape=\", numbers.shape)\n",
    "x = nn.Variable(numbers.shape)\n",
    "x.d = numbers\n",
    "relu_out = F.relu(x)\n",
    "print(\"x.shape=\", x.shape)\n",
    "print(\"relu_out.shape=\", relu_out.shape)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(x.d, relu_out.d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import nnabla.parametric_functions as PF\n",
    "import nnabla.functions as F\n",
    "\n",
    "x = nn.Variable((2, 3, 8, 8))\n",
    "x.d = np.random.random(x.shape)  # random input, just for example.\n",
    "\n",
    "nn.parameter.clear_parameters()\n",
    "with nn.parameter_scope('conv2') as param:\n",
    "    conv_out = PF.convolution(x, 2, (5, 5))\n",
    "    sig_out = F.sigmoid(conv_out)\n",
    "    \n",
    "print(sig_out)\n",
    "print(sig_out.d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametric functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nnabla as nn\n",
    "import nnabla.parametric_functions as PF\n",
    "\n",
    "x = nn.Variable.from_numpy_array(np.array([[1, 2], [3, 4]]))\n",
    "y = PF.affine(x, 4, name=\"y\")\n",
    "print(\"x\")\n",
    "print(x.d)\n",
    "print(\"y\")\n",
    "print(y.d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
