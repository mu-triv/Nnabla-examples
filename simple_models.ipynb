{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-15 12:01:59,832 [nnabla][INFO]: Initializing CPU extension...\n"
     ]
    }
   ],
   "source": [
    "import nnabla as nn\n",
    "import nnabla.functions as F\n",
    "import nnabla.parametric_functions as PF\n",
    "import numpy as np\n",
    "import nnabla.initializer as I\n",
    "from save_nnp import save_nnp\n",
    "\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib, os\n",
    "data_directory='./models'\n",
    "pathlib.Path(data_directory).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "x_size = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'-1.00 ==> 0.00'\n",
      "'-0.80 ==> 0.00'\n",
      "'-0.60 ==> 0.00'\n",
      "'-0.40 ==> 0.00'\n",
      "'-0.20 ==> 0.00'\n",
      "'-0.00 ==> 0.00'\n",
      "'0.20 ==> 0.20'\n",
      "'0.40 ==> 0.40'\n",
      "'0.60 ==> 0.60'\n",
      "'0.80 ==> 0.80'\n"
     ]
    }
   ],
   "source": [
    "nn.parameter.clear_parameters()\n",
    "x_range = (-1.0, 1.0)\n",
    "x = nn.Variable((1, 1))          # input tensor is just a vector of 1 float\n",
    "y = F.relu(x)   # output\n",
    "\n",
    "# generate data in the x_range\n",
    "for v in np.arange(x_range[0], x_range[1], (x_range[1]-x_range[0])/x_size):\n",
    "    x.d = v\n",
    "    # forward pass\n",
    "    y.forward()\n",
    "    pprint.pprint('%0.2f ==> %0.2f' % (x.d, y.d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-15 12:02:00,158 [nnabla][INFO]: Saving ./models/simple_relu.nnp as nnp\n",
      "2020-05-15 12:02:00,159 [nnabla][INFO]: Saving /tmp/tmpt54_fksn/network.nntxt as prototxt\n",
      "2020-05-15 12:02:00,161 [nnabla][INFO]: Parameter save (.protobuf): /tmp/tmpt54_fksn/parameter.protobuf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'networks': [{'name': 'simple_relu', 'batch_size': 1, 'outputs': {'y': <Variable((1, 1), need_grad=False) at 0x7f3c57ed2cb0>}, 'names': {'x': <Variable((1, 1), need_grad=False) at 0x7f3c57ed2d70>}}], 'executors': [{'name': 'Runtime', 'network': 'simple_relu', 'data': ['x'], 'output': ['y']}]}\n"
     ]
    }
   ],
   "source": [
    "simple_relu = 'simple_relu'\n",
    "nnp_file_name = os.path.join(data_directory, '%s.nnp' % simple_relu)\n",
    "batch_size = 1\n",
    "content = save_nnp(nnp_file_name, nn_name=simple_relu, input={'x': x}, output={'y': y}, batchsize=batch_size)\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'-1.00 ==> 0.27'\n",
      "'-0.80 ==> 0.31'\n",
      "'-0.60 ==> 0.35'\n",
      "'-0.40 ==> 0.40'\n",
      "'-0.20 ==> 0.45'\n",
      "'-0.00 ==> 0.50'\n",
      "'0.20 ==> 0.55'\n",
      "'0.40 ==> 0.60'\n",
      "'0.60 ==> 0.65'\n",
      "'0.80 ==> 0.69'\n"
     ]
    }
   ],
   "source": [
    "nn.parameter.clear_parameters()\n",
    "x_range = (-1.0, 1.0)\n",
    "x = nn.Variable((1, 1))          # input tensor is just a vector of 1 float\n",
    "y = F.sigmoid(x)   # output\n",
    "\n",
    "# generate data in the x_range\n",
    "for v in np.arange(x_range[0], x_range[1], (x_range[1]-x_range[0])/x_size):\n",
    "    x.d = v\n",
    "    # forward pass\n",
    "    y.forward()\n",
    "    pprint.pprint('%0.2f ==> %0.2f' % (x.d, y.d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-15 12:02:00,177 [nnabla][INFO]: Saving ./models/simple_sigmoid.nnp as nnp\n",
      "2020-05-15 12:02:00,178 [nnabla][INFO]: Saving /tmp/tmp9tvs6q2h/network.nntxt as prototxt\n",
      "2020-05-15 12:02:00,180 [nnabla][INFO]: Parameter save (.protobuf): /tmp/tmp9tvs6q2h/parameter.protobuf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'networks': [{'name': 'simple_sigmoid', 'batch_size': 1, 'outputs': {'y': <Variable((1, 1), need_grad=False) at 0x7f3c57d80110>}, 'names': {'x': <Variable((1, 1), need_grad=False) at 0x7f3c57d80410>}}], 'executors': [{'name': 'Runtime', 'network': 'simple_sigmoid', 'data': ['x'], 'output': ['y']}]}\n"
     ]
    }
   ],
   "source": [
    "simple_sigmoid = 'simple_sigmoid'\n",
    "nnp_file_name = os.path.join(data_directory, '%s.nnp' % simple_sigmoid)\n",
    "batch_size = 1\n",
    "content = save_nnp(nnp_file_name, nn_name=simple_sigmoid, input={'x': x}, output={'y': y}, batchsize=batch_size)\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'-1.00 ==> -0.76'\n",
      "'-0.80 ==> -0.66'\n",
      "'-0.60 ==> -0.54'\n",
      "'-0.40 ==> -0.38'\n",
      "'-0.20 ==> -0.20'\n",
      "'-0.00 ==> -0.00'\n",
      "'0.20 ==> 0.20'\n",
      "'0.40 ==> 0.38'\n",
      "'0.60 ==> 0.54'\n",
      "'0.80 ==> 0.66'\n"
     ]
    }
   ],
   "source": [
    "nn.parameter.clear_parameters()\n",
    "x_range = (-1.0, 1.0)\n",
    "x = nn.Variable((1, 1))          # input tensor is just a vector of 1 float\n",
    "y = F.tanh(x)   # output\n",
    "\n",
    "# generate data in the x_range\n",
    "for v in np.arange(x_range[0], x_range[1], (x_range[1]-x_range[0])/x_size):\n",
    "    x.d = v\n",
    "    # forward pass\n",
    "    y.forward()\n",
    "    pprint.pprint('%0.2f ==> %0.2f' % (x.d, y.d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-15 12:02:00,204 [nnabla][INFO]: Saving ./models/simple_tanh.nnp as nnp\n",
      "2020-05-15 12:02:00,207 [nnabla][INFO]: Saving /tmp/tmpwv0er626/network.nntxt as prototxt\n",
      "2020-05-15 12:02:00,210 [nnabla][INFO]: Parameter save (.protobuf): /tmp/tmpwv0er626/parameter.protobuf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'networks': [{'name': 'simple_tanh', 'batch_size': 1, 'outputs': {'y': <Variable((1, 1), need_grad=False) at 0x7f3c57d80b30>}, 'names': {'x': <Variable((1, 1), need_grad=False) at 0x7f3c57d80a70>}}], 'executors': [{'name': 'Runtime', 'network': 'simple_tanh', 'data': ['x'], 'output': ['y']}]}\n"
     ]
    }
   ],
   "source": [
    "simple_tanh = 'simple_tanh'\n",
    "nnp_file_name = os.path.join(data_directory, '%s.nnp' % simple_tanh)\n",
    "batch_size = 1\n",
    "content = save_nnp(nnp_file_name, nn_name=simple_tanh, input={'x': x}, output={'y': y}, batchsize=batch_size)\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SoftMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'[[-1. -1.]] ==> [[0.5 0.5]]'\n",
      "'[[-1.  0.]] ==> [[0.26894143 0.7310586 ]]'\n",
      "'[[ 0. -1.]] ==> [[0.7310586  0.26894143]]'\n",
      "'[[0. 0.]] ==> [[0.5 0.5]]'\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "x_size = 2\n",
    "nn.parameter.clear_parameters()\n",
    "x_range = (-1.0, 1.0)\n",
    "x = nn.Variable((1, 2))          # input tensor is just a vector of 1 float\n",
    "y = F.softmax(x)   # output\n",
    "\n",
    "# generate data in the x_range\n",
    "for v0 in np.arange(x_range[0], x_range[1], (x_range[1]-x_range[0])/x_size):\n",
    "    for v1 in np.arange(x_range[0], x_range[1], (x_range[1]-x_range[0])/x_size):\n",
    "        x.d = numpy.array([v0, v1])\n",
    "        # forward pass\n",
    "        y.forward()\n",
    "        pprint.pprint('%s ==> %s' % (str(x.d), str(y.d)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-15 12:02:00,233 [nnabla][INFO]: Saving ./models/simple_softmax.nnp as nnp\n",
      "2020-05-15 12:02:00,234 [nnabla][INFO]: Saving /tmp/tmp6l1esuz4/network.nntxt as prototxt\n",
      "2020-05-15 12:02:00,236 [nnabla][INFO]: Parameter save (.protobuf): /tmp/tmp6l1esuz4/parameter.protobuf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'networks': [{'name': 'simple_softmax', 'batch_size': 1, 'outputs': {'y': <Variable((1, 2), need_grad=False) at 0x7f3c57d80530>}, 'names': {'x': <Variable((1, 2), need_grad=False) at 0x7f3c57ed2cb0>}}], 'executors': [{'name': 'Runtime', 'network': 'simple_softmax', 'data': ['x'], 'output': ['y']}]}\n"
     ]
    }
   ],
   "source": [
    "simple_softmax = 'simple_softmax'\n",
    "nnp_file_name = os.path.join(data_directory, '%s.nnp' % simple_softmax)\n",
    "batch_size = 1\n",
    "content = save_nnp(nnp_file_name, nn_name=simple_softmax, input={'x': x}, output={'y': y}, batchsize=batch_size)\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Neuron Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nnabla as nn\n",
    "import nnabla.functions as F\n",
    "import nnabla.parametric_functions as PF\n",
    "import numpy as np\n",
    "import nnabla.initializer as I\n",
    "from save_nnp import save_nnp\n",
    "\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib, os\n",
    "data_directory='./models'\n",
    "pathlib.Path(data_directory).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "x_size = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('affine/W',\n",
      "              <Variable((5, 1), need_grad=True) at 0x7f3c57d94b30>)])\n",
      "array([[-0.06689208],\n",
      "       [ 0.01002087],\n",
      "       [ 0.07217436],\n",
      "       [ 0.02358674],\n",
      "       [ 0.08924928]])\n",
      "array([[-1. , -0.6, -0.2,  0.2,  0.6]])\n"
     ]
    }
   ],
   "source": [
    "nn.parameter.clear_parameters()\n",
    "rng = np.random.seed(2345)\n",
    "initializer = I.UniformInitializer((-0.1, 0.1), rng=rng)\n",
    "\n",
    "x_range = (-1.0, 1.0)\n",
    "x = nn.Variable((1, x_size))          # input tensor is just a vector of x_size floats\n",
    "y = PF.affine(x, 1, w_init=initializer, with_bias=False)\n",
    "\n",
    "pprint.pprint(nn.get_parameters())\n",
    "pprint.pprint(nn.get_parameters()['affine/W'].d)\n",
    "\n",
    "# generate data in the x_range\n",
    "x.d = np.arange(x_range[0], x_range[1], (x_range[1]-x_range[0])/x_size)\n",
    "pprint.pprint(x.d)\n",
    "\n",
    "# forward pass\n",
    "y.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[0.10471159]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(y.d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-15 12:02:00,281 [nnabla][INFO]: Saving ./models/simple_model_affine.nnp as nnp\n",
      "2020-05-15 12:02:00,282 [nnabla][INFO]: Saving /tmp/tmpv05vbeq8/network.nntxt as prototxt\n",
      "2020-05-15 12:02:00,286 [nnabla][INFO]: Parameter save (.protobuf): /tmp/tmpv05vbeq8/parameter.protobuf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'networks': [{'name': 'simple_model_affine', 'batch_size': 1, 'outputs': {'y': <Variable((1, 1), need_grad=True) at 0x7f3c57d94bf0>}, 'names': {'x': <Variable((1, 5), need_grad=False) at 0x7f3c5e152d70>}}], 'executors': [{'name': 'Runtime', 'network': 'simple_model_affine', 'data': ['x'], 'output': ['y']}]}\n"
     ]
    }
   ],
   "source": [
    "simple_model_affine = 'simple_model_affine'\n",
    "nnp_file_name = os.path.join(data_directory, '%s.nnp' % simple_model_affine)\n",
    "batch_size = 1\n",
    "content = save_nnp(nnp_file_name, nn_name=simple_model_affine, input={'x': x}, output={'y': y}, batchsize=batch_size)\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('affine/W',\n",
      "              <Variable((5, 1), need_grad=True) at 0x7f3c57d947d0>)])\n",
      "array([[ 0.01217159],\n",
      "       [ 0.0739175 ],\n",
      "       [-0.06551991],\n",
      "       [-0.00955659],\n",
      "       [ 0.00522653]])\n",
      "array([[-1. , -0.6, -0.2,  0.2,  0.6]])\n"
     ]
    }
   ],
   "source": [
    "nn.parameter.clear_parameters()\n",
    "rng = np.random.seed(11579)\n",
    "initializer = I.UniformInitializer((-0.1, 0.1), rng=rng)\n",
    "\n",
    "x_range = (-1.0, 1.0)\n",
    "x = nn.Variable((1, x_size))          # input tensor is just a vector of x_size floats\n",
    "y0 = PF.affine(x, 1, w_init=initializer, with_bias=False)\n",
    "y = F.relu(y0)   # output\n",
    "\n",
    "pprint.pprint(nn.get_parameters())\n",
    "pprint.pprint(nn.get_parameters()['affine/W'].d)\n",
    "\n",
    "# generate data in the x_range\n",
    "x.d = np.arange(x_range[0], x_range[1], (x_range[1]-x_range[0])/x_size)\n",
    "pprint.pprint(x.d)\n",
    "\n",
    "# forward pass\n",
    "y.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[-0.04219351]], dtype=float32)\n",
      "array([[0.]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(y0.d)\n",
    "pprint.pprint(y.d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-15 12:02:00,325 [nnabla][INFO]: Saving ./models/simple_model_relu.nnp as nnp\n",
      "2020-05-15 12:02:00,327 [nnabla][INFO]: Saving /tmp/tmp2a1t611g/network.nntxt as prototxt\n",
      "2020-05-15 12:02:00,331 [nnabla][INFO]: Parameter save (.protobuf): /tmp/tmp2a1t611g/parameter.protobuf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'networks': [{'name': 'simple_model_relu', 'batch_size': 1, 'outputs': {'y0': <Variable((1, 1), need_grad=True) at 0x7f3c57d94770>, 'y': <Variable((1, 1), need_grad=True) at 0x7f3c57d94890>}, 'names': {'x': <Variable((1, 5), need_grad=False) at 0x7f3c57d94b30>}}], 'executors': [{'name': 'Runtime', 'network': 'simple_model_relu', 'data': ['x'], 'output': ['y0', 'y']}]}\n"
     ]
    }
   ],
   "source": [
    "simple_model_relu = 'simple_model_relu'\n",
    "nnp_file_name = os.path.join(data_directory, '%s.nnp' % simple_model_relu)\n",
    "batch_size = 1\n",
    "content = save_nnp(nnp_file_name, nn_name=simple_model_relu, input={'x': x}, output={'y0':y0, 'y': y}, batchsize=batch_size)\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('affine/W',\n",
      "              <Variable((5, 1), need_grad=True) at 0x7f3c57daabf0>)])\n",
      "array([[-0.01273317],\n",
      "       [ 0.05659582],\n",
      "       [ 0.01842164],\n",
      "       [-0.04010906],\n",
      "       [ 0.07028222]])\n",
      "array([[-1. , -0.6, -0.2,  0.2,  0.6]])\n"
     ]
    }
   ],
   "source": [
    "nn.parameter.clear_parameters()\n",
    "rng = np.random.seed(1393)\n",
    "initializer = I.UniformInitializer((-0.1, 0.1), rng=rng)\n",
    "\n",
    "x_range = (-1.0, 1.0)\n",
    "x = nn.Variable((1, x_size))          # input tensor is just a vector of x_size floats\n",
    "y0 = PF.affine(x, 1, w_init=initializer, with_bias=False)\n",
    "y = F.sigmoid(y0)   # output\n",
    "\n",
    "pprint.pprint(nn.get_parameters())\n",
    "pprint.pprint(nn.get_parameters()['affine/W'].d)\n",
    "\n",
    "# generate data in the x_range\n",
    "x.d = np.arange(x_range[0], x_range[1], (x_range[1]-x_range[0])/x_size)\n",
    "pprint.pprint(x.d)\n",
    "\n",
    "# forward pass\n",
    "y.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[0.00923887]], dtype=float32)\n",
      "array([[0.5023097]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(y0.d)\n",
    "pprint.pprint(y.d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-15 12:02:00,370 [nnabla][INFO]: Saving ./models/simple_model_sigmoid.nnp as nnp\n",
      "2020-05-15 12:02:00,371 [nnabla][INFO]: Saving /tmp/tmp978zi2wz/network.nntxt as prototxt\n",
      "2020-05-15 12:02:00,376 [nnabla][INFO]: Parameter save (.protobuf): /tmp/tmp978zi2wz/parameter.protobuf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'networks': [{'name': 'simple_model_sigmoid', 'batch_size': 1, 'outputs': {'y0': <Variable((1, 1), need_grad=True) at 0x7f3c57daad10>, 'y': <Variable((1, 1), need_grad=True) at 0x7f3c57daad70>}, 'names': {'x': <Variable((1, 5), need_grad=False) at 0x7f3c57d947d0>}}], 'executors': [{'name': 'Runtime', 'network': 'simple_model_sigmoid', 'data': ['x'], 'output': ['y0', 'y']}]}\n"
     ]
    }
   ],
   "source": [
    "simple_model_sigmoid = 'simple_model_sigmoid'\n",
    "nnp_file_name = os.path.join(data_directory, '%s.nnp' % simple_model_sigmoid)\n",
    "batch_size = 1\n",
    "content = save_nnp(nnp_file_name, nn_name=simple_model_sigmoid, input={'x': x}, output={'y0': y0, 'y': y}, batchsize=batch_size)\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('affine/W',\n",
      "              <Variable((5, 1), need_grad=True) at 0x7f3c57db9950>)])\n",
      "array([[-0.08689096],\n",
      "       [ 0.00578396],\n",
      "       [-0.08795961],\n",
      "       [ 0.05258294],\n",
      "       [ 0.01774052]])\n",
      "array([[-1. , -0.6, -0.2,  0.2,  0.6]])\n"
     ]
    }
   ],
   "source": [
    "nn.parameter.clear_parameters()\n",
    "rng = np.random.seed(8853)\n",
    "initializer = I.UniformInitializer((-0.1, 0.1), rng=rng)\n",
    "\n",
    "x_range = (-1.0, 1.0)\n",
    "x = nn.Variable((1, x_size))          # input tensor is just a vector of x_size floats\n",
    "y0 = PF.affine(x, 1, w_init=initializer, with_bias=False)\n",
    "y = F.tanh(y0)   # output\n",
    "\n",
    "pprint.pprint(nn.get_parameters())\n",
    "pprint.pprint(nn.get_parameters()['affine/W'].d)\n",
    "\n",
    "# generate data in the x_range\n",
    "x.d = np.arange(x_range[0], x_range[1], (x_range[1]-x_range[0])/x_size)\n",
    "pprint.pprint(x.d)\n",
    "\n",
    "# forward pass\n",
    "y.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[0.1221734]], dtype=float32)\n",
      "array([[0.12156913]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(y0.d)\n",
    "pprint.pprint(y.d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-15 12:02:00,413 [nnabla][INFO]: Saving ./models/simple_model_tanh.nnp as nnp\n",
      "2020-05-15 12:02:00,415 [nnabla][INFO]: Saving /tmp/tmp3b6s5vaq/network.nntxt as prototxt\n",
      "2020-05-15 12:02:00,419 [nnabla][INFO]: Parameter save (.protobuf): /tmp/tmp3b6s5vaq/parameter.protobuf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'networks': [{'name': 'simple_model_tanh', 'batch_size': 1, 'outputs': {'y0': <Variable((1, 1), need_grad=True) at 0x7f3c57ed2d70>, 'y': <Variable((1, 1), need_grad=True) at 0x7f3c57db9890>}, 'names': {'x': <Variable((1, 5), need_grad=False) at 0x7f3c57daabf0>}}], 'executors': [{'name': 'Runtime', 'network': 'simple_model_tanh', 'data': ['x'], 'output': ['y0', 'y']}]}\n"
     ]
    }
   ],
   "source": [
    "simple_model_tanh = 'simple_model_tanh'\n",
    "nnp_file_name = os.path.join(data_directory, '%s.nnp' % simple_model_tanh)\n",
    "batch_size = 1\n",
    "content = save_nnp(nnp_file_name, nn_name=simple_model_tanh, input={'x': x}, output={'y0': y0, 'y': y}, batchsize=batch_size)\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SoftMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('affine/W',\n",
      "              <Variable((5, 2), need_grad=True) at 0x7f3c57d944d0>)])\n",
      "array([[-0.00840704, -0.02306222],\n",
      "       [-0.04123034, -0.06403097],\n",
      "       [ 0.02346617, -0.05210479],\n",
      "       [-0.09995786,  0.05643672],\n",
      "       [ 0.00512868, -0.01903969]])\n",
      "array([[-1. , -0.6, -0.2,  0.2,  0.6]])\n"
     ]
    }
   ],
   "source": [
    "nn.parameter.clear_parameters()\n",
    "rng = np.random.seed(63452)\n",
    "initializer = I.UniformInitializer((-0.1, 0.1), rng=rng)\n",
    "\n",
    "y0_size = 2\n",
    "x_range = (-1.0, 1.0)\n",
    "x = nn.Variable((1, x_size))          # input tensor is just a vector of 5 floats\n",
    "y0 = PF.affine(x, y0_size, w_init=initializer, with_bias=False)\n",
    "y = F.softmax(y0)   # output\n",
    "\n",
    "pprint.pprint(nn.get_parameters())\n",
    "pprint.pprint(nn.get_parameters()['affine/W'].d)\n",
    "\n",
    "# generate data in the x_range\n",
    "x.d = np.arange(x_range[0], x_range[1], (x_range[1]-x_range[0])/x_size)\n",
    "pprint.pprint(x.d)\n",
    "\n",
    "# forward pass\n",
    "y.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[0.01153764, 0.07176528]], dtype=float32)\n",
      "array([[0.48494762, 0.5150523 ]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(y0.d)\n",
    "pprint.pprint(y.d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-15 12:02:00,468 [nnabla][INFO]: Saving ./models/simple_model_softmax.nnp as nnp\n",
      "2020-05-15 12:02:00,469 [nnabla][INFO]: Saving /tmp/tmpd8wqqpwt/network.nntxt as prototxt\n",
      "2020-05-15 12:02:00,476 [nnabla][INFO]: Parameter save (.protobuf): /tmp/tmpd8wqqpwt/parameter.protobuf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'networks': [{'name': 'simple_model_softmax', 'batch_size': 1, 'outputs': {'y0': <Variable((1, 2), need_grad=True) at 0x7f3c57daab30>, 'y': <Variable((1, 2), need_grad=True) at 0x7f3c57daa0b0>}, 'names': {'x': <Variable((1, 5), need_grad=False) at 0x7f3c57daa6b0>}}], 'executors': [{'name': 'Runtime', 'network': 'simple_model_softmax', 'data': ['x'], 'output': ['y0', 'y']}]}\n"
     ]
    }
   ],
   "source": [
    "simple_model_softmax = 'simple_model_softmax'\n",
    "nnp_file_name = os.path.join(data_directory, '%s.nnp' % simple_model_softmax)\n",
    "batch_size = 1\n",
    "content = save_nnp(nnp_file_name, nn_name=simple_model_softmax, input={'x': x}, output={'y0': y0, 'y': y}, batchsize=batch_size)\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert NNP to NNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert from NNP to NNB\n",
    "import subprocess, time\n",
    "\n",
    "models = [\n",
    "    simple_model_affine,\n",
    "    simple_model_relu,\n",
    "    simple_model_sigmoid, \n",
    "    simple_model_tanh,\n",
    "    simple_model_softmax,\n",
    "    simple_relu,\n",
    "    simple_sigmoid, \n",
    "    simple_tanh,\n",
    "    simple_softmax\n",
    "]\n",
    "\n",
    "# file format conversion\n",
    "for model_name in models:\n",
    "    nnp_fname = os.path.join(data_directory, '%s.nnp' % model_name)\n",
    "    nnb_fname = os.path.join(data_directory, '%s.nnb' % model_name)\n",
    "    out = subprocess.Popen(['nnabla_cli', 'convert', '-b', '%d' % batch_size, nnp_fname, nnb_fname])\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "# verification\n",
    "for model_name in models:\n",
    "    nnp_fname = os.path.join(data_directory, '%s.nnp' % model_name)\n",
    "    nnb_fname = os.path.join(data_directory, '%s.nnb' % model_name)\n",
    "    assert(os.path.exists(nnb_fname))\n",
    "    assert(os.path.isfile(nnb_fname))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert NNB to C-style\n",
    "This conversion uses the bin2array https://github.com/Jamesits/bin2array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file format conversion\n",
    "for model_name in models:\n",
    "    nnb_fname = os.path.join(data_directory, '%s.nnb' % model_name)\n",
    "    c_header_fname = os.path.join(data_directory, '%s.h' % model_name)\n",
    "    out = subprocess.Popen(['python3', 'bin2array/bin2array.py', '-O', c_header_fname, nnb_fname])\n",
    "\n",
    "time.sleep(5)\n",
    "    \n",
    "# verification\n",
    "for model_name in models:\n",
    "    c_header_fname = os.path.join(data_directory, '%s.h' % model_name)\n",
    "    assert(os.path.exists(c_header_fname))\n",
    "    assert(os.path.isfile(c_header_fname))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_range = (-10.0, 10.0)\n",
    "n_samples = 10\n",
    "test_c_header_fname = os.path.join(data_directory, 'test_data.h')\n",
    "\n",
    "# generate data in the x_range\n",
    "a = np.arange(x_range[0], x_range[1], (x_range[1]-x_range[0])/(x_size*n_samples))\n",
    "b = np.reshape(a, (-1, x_size))\n",
    "c_str = ',\\n'.join([','.join([str(e) for e in row]) for row in b])\n",
    "\n",
    "with open(test_c_header_fname, 'w') as f:\n",
    "    f.write(c_str)\n",
    "\n",
    "time.sleep(5)\n",
    "    \n",
    "# verification\n",
    "assert(os.path.exists(test_c_header_fname))\n",
    "assert(os.path.isfile(test_c_header_fname))            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load models, run inferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'########## simple_model_affine ##########'\n",
      "{'affine/W': <Variable((5, 1), need_grad=True) at 0x7f3c5496d830>,\n",
      " 'x': <Variable((1, 5), need_grad=False) at 0x7f3c5496d890>,\n",
      " 'y': <Variable((1, 1), need_grad=True) at 0x7f3c5496dd70>}\n",
      "<Variable((1, 5), need_grad=False) at 0x7f3c5496d890>\n",
      "<Variable((1, 1), need_grad=True) at 0x7f3c5496dd70>\n",
      "array([[-1.0485411]], dtype=float32)\n",
      "array([[-0.7922627]], dtype=float32)\n",
      "array([[-0.5359843]], dtype=float32)\n",
      "array([[-0.279706]], dtype=float32)\n",
      "array([[-0.02342759]], dtype=float32)\n",
      "array([[0.23285078]], dtype=float32)\n",
      "array([[0.48912913]], dtype=float32)\n",
      "array([[0.7454075]], dtype=float32)\n",
      "array([[1.0016859]], dtype=float32)\n",
      "array([[1.2579644]], dtype=float32)\n",
      "'########## simple_model_relu ##########'\n",
      "{'affine/W': <Variable((5, 1), need_grad=True) at 0x7f3c5497e3b0>,\n",
      " 'x': <Variable((1, 5), need_grad=False) at 0x7f3c5497e350>,\n",
      " 'y': <Variable((1, 1), need_grad=True) at 0x7f3c5497e4d0>,\n",
      " 'y0': <Variable((1, 1), need_grad=True) at 0x7f3c5497e470>}\n",
      "<Variable((1, 5), need_grad=False) at 0x7f3c5497e350>\n",
      "<Variable((1, 1), need_grad=True) at 0x7f3c5497e4d0>\n",
      "array([[0.]], dtype=float32)\n",
      "array([[0.]], dtype=float32)\n",
      "array([[0.]], dtype=float32)\n",
      "array([[0.]], dtype=float32)\n",
      "array([[0.]], dtype=float32)\n",
      "array([[0.23285078]], dtype=float32)\n",
      "array([[0.48912913]], dtype=float32)\n",
      "array([[0.7454075]], dtype=float32)\n",
      "array([[1.0016859]], dtype=float32)\n",
      "array([[1.2579644]], dtype=float32)\n",
      "'########## simple_model_sigmoid ##########'\n",
      "{'affine/W': <Variable((5, 1), need_grad=True) at 0x7f3c5497e6b0>,\n",
      " 'x': <Variable((1, 5), need_grad=False) at 0x7f3c5497e650>,\n",
      " 'y': <Variable((1, 1), need_grad=True) at 0x7f3c5497e7d0>,\n",
      " 'y0': <Variable((1, 1), need_grad=True) at 0x7f3c5497e770>}\n",
      "<Variable((1, 5), need_grad=False) at 0x7f3c5497e650>\n",
      "<Variable((1, 1), need_grad=True) at 0x7f3c5497e7d0>\n",
      "array([[0.25950536]], dtype=float32)\n",
      "array([[0.31168303]], dtype=float32)\n",
      "array([[0.3691222]], dtype=float32)\n",
      "array([[0.43052584]], dtype=float32)\n",
      "array([[0.4941434]], dtype=float32)\n",
      "array([[0.5579511]], dtype=float32)\n",
      "array([[0.61990124]], dtype=float32)\n",
      "array([[0.6781772]], dtype=float32)\n",
      "array([[0.73138994]], dtype=float32)\n",
      "array([[0.7786755]], dtype=float32)\n",
      "'########## simple_model_tanh ##########'\n",
      "{'affine/W': <Variable((5, 1), need_grad=True) at 0x7f3c5497ea10>,\n",
      " 'x': <Variable((1, 5), need_grad=False) at 0x7f3c5497e4d0>,\n",
      " 'y': <Variable((1, 1), need_grad=True) at 0x7f3c5497eb30>,\n",
      " 'y0': <Variable((1, 1), need_grad=True) at 0x7f3c5497ead0>}\n",
      "<Variable((1, 5), need_grad=False) at 0x7f3c5497e4d0>\n",
      "<Variable((1, 1), need_grad=True) at 0x7f3c5497eb30>\n",
      "array([[-0.7812385]], dtype=float32)\n",
      "array([[-0.6596889]], dtype=float32)\n",
      "array([[-0.48994225]], dtype=float32)\n",
      "array([[-0.27263296]], dtype=float32)\n",
      "array([[-0.02342331]], dtype=float32)\n",
      "array([[0.22873172]], dtype=float32)\n",
      "array([[0.45352498]], dtype=float32)\n",
      "array([[0.63240117]], dtype=float32)\n",
      "array([[0.76230127]], dtype=float32)\n",
      "array([[0.85050195]], dtype=float32)\n",
      "'########## simple_model_softmax ##########'\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "An error occurs during creation of a variable `affine/W` as a parameter variable. The error was:\n----\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.7/dist-packages/nnabla/utils/nnp_graph.py\", line 283, in _get_variable_or_create\n    assert shape == param.shape\nAssertionError\n\n----\nThe parameters registered was affine/W",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nnabla/utils/nnp_graph.py\u001b[0m in \u001b[0;36m_get_variable_or_create\u001b[0;34m(self, v, callback, current_scope)\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m                 \u001b[0;32massert\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m                 \u001b[0mparam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_unlinked_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneed_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneed_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-0bd94d9b4f70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mnw_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_network_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mpprint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s %s %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'#'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnw_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'#'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnw_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mpprint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nnabla/utils/nnp_graph.py\u001b[0m in \u001b[0;36mget_network\u001b[0;34m(self, name, batch_size, callback)\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0mnetwork_proto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnnabla_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m         \u001b[0mnetwork_proto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mNnpNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork_proto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nnabla/utils/nnp_graph.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, network_proto, scope, batch_size, rng, callback)\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameter_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_functions_in_forward_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m                 \u001b[0;31m# print(f.name)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m                 \u001b[0mnum_ops\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nnabla/utils/nnp_graph.py\u001b[0m in \u001b[0;36m_create_function\u001b[0;34m(self, f, callback, current_scope)\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_generate_function_by_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_generate_function_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m         \u001b[0mfunction_instance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nnabla/utils/nnp_graph.py\u001b[0m in \u001b[0;36m_create_inputs\u001b[0;34m(self, inputs, callback, current_scope)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             input_vars.append(self._get_variable_or_create(\n\u001b[0;32m--> 325\u001b[0;31m                 i, callback, current_scope))\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput_vars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nnabla/utils/nnp_graph.py\u001b[0m in \u001b[0;36m_get_variable_or_create\u001b[0;34m(self, v, callback, current_scope)\u001b[0m\n\u001b[1;32m    311\u001b[0m                     \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_exc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m                     '\\n'.join(\n\u001b[0;32m--> 313\u001b[0;31m                         list(nn.get_parameters(grad_only=False).keys()))))\n\u001b[0m\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: An error occurs during creation of a variable `affine/W` as a parameter variable. The error was:\n----\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.7/dist-packages/nnabla/utils/nnp_graph.py\", line 283, in _get_variable_or_create\n    assert shape == param.shape\nAssertionError\n\n----\nThe parameters registered was affine/W"
     ]
    }
   ],
   "source": [
    "from nnabla.utils.nnp_graph import NnpLoader\n",
    "\n",
    "nn.parameter.clear_parameters()\n",
    "\n",
    "for model_name in models:\n",
    "    nnp_fname = os.path.join(data_directory, '%s.nnp' % model_name)\n",
    "    # Read a .nnp file.\n",
    "    nnp = NnpLoader(nnp_fname)\n",
    "    nw_name = nnp.get_network_names()[0]\n",
    "    pprint.pprint('%s %s %s' % ('#' * 10, nw_name, '#' * 10))\n",
    "    net = nnp.get_network(nw_name)\n",
    "    pprint.pprint(net.variables)\n",
    "    x = net.inputs['x']\n",
    "    y = net.outputs['y']\n",
    "    pprint.pprint(x)\n",
    "    pprint.pprint(y)\n",
    "    for d in b:\n",
    "        x.d = d\n",
    "        y.forward()\n",
    "        pprint.pprint(y.d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
